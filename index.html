<!DOCTYPE html>
<html lang="en">
<head>
  <title>Where can I find my home?</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-vis"></script>
</head>
<body>

<script type="text/javascript">
// train model, evaluate loss, update and optimize model and repeat for next epoch.
// test is not iterative, just evaluate against test dataset and evaluate loss and compare with train
// if close, well trained. if too diff, may overfitted or data was not prepared properly, not shuffled
// validation dataset for frequent evaluation of model independent from train set, testing reserved for final stage


// http-server

// TensorFlow.js can import data from CSV file via HTTP (or the local file system when using Node.js).
// The tfjs-vis library can to help you visualise data when using TensorFlow.js
// Features and labels should be stored in 2D tensors to feed into the model.
// Features and labels should be normalized to a range between 0 and 1.
// You can normalise using min-max normalization, implemented with tensor operations.
// You need to keep track of the minimum and maximum values to later denormalise.
// Tensors can be split into sub tensors in any ratio using tf.split(...)

  // async func to plot and visualize our data 
  async function plot(pointsArray, featureName) {
    tfvis.render.scatterplot(
      { name: `${featureName} vs House Price` },
      { values: [pointsArray], series: ["original"] },
      {
        xLabel: featureName,
        yLabel: "Price",
      }
    )
  }

  function normalize(tensor) {
    // method: https://en.wikipedia.org/wiki/Feature_scaling#Rescaling_(min-max_normalization)
    //  every value be in range 0 and 1
    const min = tensor.min();
    const max = tensor.max();
    const normalizedTensor = tensor.sub(min).div(max.sub(min));
    return {
      tensor: normalizedTensor,
      min,
      max
    };
  }

  function denormalize(tensor, min, max) {
    // denormalize tensors if needed later
    const denormalizedTensor = tensor.mul(max.sub(min)).add(min);
    return denormalizedTensor;
  }

  function createModel() {
    // sequential model, output of a layer is the input of next layer
    const model = tf.sequential();

    // single layer, single node, linear
    // dense, all inputs and outputs are connected
    model.add(tf.layers.dense({
      units: 1,
      useBias: true,
      activation: 'linear',
      inputDim: 1,
    }));

    // optimizer
    // stochastic gradient descent builtin optimizer, with a learning rate of 0.1
    // 0.1: good starting point
    // 0.01: reduced by factor 10, more epochs to train
    // 0.001: taking longer to min
    // 0.5: wobbly moving away from min, bit too large
    // 1.0: very much too large, diverging away from min
    // adam: different optimizer algorithm, works effectively without learning rate, the algo adapts leraning rate over epochs
    const optimizer = tf.train.sgd(0.1);

    // prepares model for training and testing, chose loss func from builtin tf.loss.meanSquaredError
    // RMSE with already normalized data is overkill, so we just use MSE
    model.compile({
      loss: 'meanSquaredError',
      optimizer,
    });

    return model;
  }
  
  // async func to train model
  async function trainModel (model, trainingFeatureTensor, trainingLabelTensor) {

    // visualize the training progress - loss
    const { onBatchEnd, onEpochEnd } = tfvis.show.fitCallbacks(
      { name: "Training" },
      ['loss']
    );

    // fit method to train for a certain number of epochs, used 20 first, then 30
    return model.fit(trainingFeatureTensor, trainingLabelTensor, {
      batchSize: 32,
      epochs: 30,
      validationSplit: 0.2,
      callbacks: {
        onEpochEnd
        // to log loss values on each epochs
        // onEpochEnd: (epoch, log) => console.log(`Epoch ${epoch}: loss = ${log.loss}`)
      }
    });
  }


  async function run () {

    // Ensure tensorflow is initialized and ready
    await tf.ready();

    // Import from csv file
    const housingData = tf.data.csv("http://127.0.0.1:8080/nyc_housing.csv");

    // Extract x and y values to plot
    const pointsDataset = housingData.map(record => ({
      x: record.sqfeet,
      y: record.price,
    }));
    const points = await pointsDataset.toArray();

    // to fix error of evenly split data into training and testing, we remove one element if odd
    if(points.length % 2 !== 0) { // If odd number of elements
      points.pop(); // remove one element
    }

    // shuffle data to avoid patterns in order of data or prices by area
    // so no split of data gets more than others on a category or group of values
    tf.util.shuffle(points);
    plot(points, "Square Feet");

    // Extract Features (inputs)
    const featureValues = points.map(p => p.x);
    const featureTensor = tf.tensor2d(featureValues, [featureValues.length, 1]);

    // Extract Labels (outputs)
    const labelValues = points.map(p => p.y);
    const labelTensor = tf.tensor2d(labelValues, [labelValues.length, 1]);

    // featureTensor.print()
    // labelTensor.print()

    // Normalize features and labels
    const normalizedFeature = normalize(featureTensor);
    const normalizedLabel = normalize(labelTensor);

    // normalizedFeature.tensor.print()
    // normalizedLabel.tensor.print()

    // split train and test into 50 - 50 , equally sized datasets
    const [trainingFeatureTensor, testingFeatureTensor] = tf.split(normalizedFeature.tensor, 2);
    const [trainingLabelTensor, testingLabelTensor] = tf.split(normalizedLabel.tensor, 2);

    // trainingFeatureTensor.print()
    // trainingLabelTensor.print()

    const model = createModel();
    // inspect model
    tfvis.show.modelSummary({ name: "Model summary" }, model);

    // to innspect details of layers, first layer
    const layer = model.getLayer(undefined, 0);
    tfvis.show.layer({ name: "Layer 1" }, layer);

    const result = await trainModel(model, trainingFeatureTensor, trainingLabelTensor);
    console.log(result);
    const trainingLoss = result.history.loss.pop();
    console.log(`Training set loss: ${trainingLoss}`);
    const validationLoss = result.history.val_loss.pop();
    console.log(`Validation set loss: ${validationLoss}`);

    const lossTensor = model.evaluate(testingFeatureTensor, testingLabelTensor);
    const loss = await lossTensor.dataSync();
    console.log(`Testing set loss: ${loss}`);

  }

  run();
</script>

</body>
</html>